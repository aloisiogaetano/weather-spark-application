# Weather Spark Application
## ğŸ“Œ Overview

Questo progetto implementa una pipeline di data processing utilizzando Apache Spark per lâ€™analisi di dati meteorologici storici.
Lâ€™obiettivo Ã¨ dimostrare la capacitÃ  di:

progettare trasformazioni Spark robuste

gestire dati reali e potenzialmente sporchi

strutturare un progetto scalabile e testabile

Il progetto risponde a tre task analitici distinti, ognuno implementato come job indipendente ma orchestrato tramite un unico entrypoint (main.py).

## ğŸ§± Struttura del Progetto
```
weather-spark-app/
â”‚
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile.dockerfile
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”œâ”€â”€ clear_days.py
â”‚   â”‚   â”œâ”€â”€ nation_stats.py
â”‚   â”‚   â””â”€â”€ seasonal_range.py
â”‚   â”‚
â”‚   â”œâ”€â”€ transformations/
â”‚   â”‚   â”œâ”€â”€ wide_to_long.py
â”‚   â”‚   â”œâ”€â”€ join_metrics.py
â”‚   â”‚   â”œâ”€â”€ convert_to_local.py
â”‚   â”‚   â”œâ”€â”€ add_season.py
â”‚   â”‚   â”œâ”€â”€ clear_days_logic.py
â”‚   â”‚   â””â”€â”€ aggregate_*.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ spark_session.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_clear_days_logic.py
â”‚   â”œâ”€â”€ test_nation_stats.py
â”‚   â””â”€â”€ test_seasonal_range.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### âš™ï¸ Scelte Implementative (Design Decisions)
Tecnologie

Apache Spark 3.5.1 (PySpark 3.5.1)
Scelto per la sua capacitÃ  di gestire grandi volumi di dati, API dichiarative e ampia diffusione in ambienti enterprise.

Docker
Garantisce riproducibilitÃ  dellâ€™ambiente, isolamento delle dipendenze e portabilitÃ .

PyTest
Per test unitari e di integrazione sulle trasformazioni Spark.

### ğŸ§  Gestione dei Dati
Dataset Wide â†’ Long

Tutti i dataset meteorologici (temperature, pressure, humidity) sono forniti in formato wide, con una colonna per ogni cittÃ .

ğŸ‘‰ Ãˆ stata introdotta una transformation comune **reshape_wide_to_long** per:

- normalizzare i dati

- semplificare join e aggregazioni

- rendere il codice riutilizzabile e testabile

ğŸ‘‰ Dati Sporchi e Assunzioni:

- Valori nulli gestiti tramite filtri espliciti o ignorati durante le aggregazioni (comportamento standard Spark).

- Le conversioni datetime sono centralizzate e mappate con i rispettivi timezone.

- CittÃ  non presenti in tutti i dataset: le join sono effettuate in modo conservativo (inner/left join a seconda del contesto).

### ğŸ“Š Task 1 â€“ Analisi del Tempo Sereno in Primavera
Obiettivo

Per ogni anno, individuare le cittÃ  che hanno avuto almeno 15 giorni al mese (marzo, aprile, maggio) con tempo sereno.

Scelte Chiave

Un â€œgiorno serenoâ€ Ã¨ definito come un giorno con â‰¥ 18 ore di "sky is clear".

Le descrizioni meteo sono aggregate:

ora â†’ giorno

giorno â†’ mese

mese â†’ anno

I mesi primaverili sono valutati in AND (tutti devono soddisfare il criterio).

API Spark Utilizzate

- groupBy

- count

- filter

- funzioni datetime

ğŸŒ Task 2 â€“ Statistiche Meteorologiche per Nazione
Obiettivo

Calcolare per ogni nazione, mese e anno:

media

deviazione standard

minimo

massimo
di temperatura, pressione e umiditÃ .

Scelte Chiave

Tutti i dataset vengono:

normalizzati (wide â†’ long)

rinominati semanticamente (temperature, pressure, humidity)

joinati su (datetime, city)

Join con city_attributes.csv per ottenere la nazione

Conversione degli orari da UTC a fuso locale tramite mapping cittÃ  â†’ timezone

Motivazione

Separare:

logica di reshaping

logica di join

logica di aggregazione

rende il codice:

testabile

riutilizzabile

facilmente estendibile

ğŸŒ¡ï¸ Task 3 â€“ Escursione Termica Stagionale (Top 3 CittÃ )
Obiettivo

Per ogni nazione, individuare nel 2017 le 3 cittÃ  con la maggiore differenza tra:

temperatura media periodo caldo (giugnoâ€“settembre)

temperatura media periodo freddo (gennaioâ€“aprile)

considerando solo la fascia oraria locale 12:00â€“15:00.

Scelte Chiave

Introduzione esplicita del concetto di stagione (add_season)

I mesi fuori dai periodi definiti vengono esclusi

Le medie stagionali sono calcolate aggregando tutti i mesi del periodo

Ranking per nazione tramite Window + row_number

Test

Verifica assegnazione stagioni

Verifica calcolo differenza termica

Verifica ranking top 3 per nazione

ğŸ§ª Testing

I test usano una SparkSession reale

Nessun mock di Spark â†’ comportamento realistico

Le transformation sono testate isolatamente

Ãˆ presente conftest.py per inizializzare Spark una sola volta

Esecuzione test:

docker-compose run --rm spark-app pytest

ğŸš€ Come Avviare il Progetto
Prerequisiti

Docker â‰¥ 20.x

Docker Compose

Build dellâ€™ambiente
docker-compose build

Esecuzione Task
Task 1
docker-compose run --rm spark-app \
  python src/main.py task1 data/raw/weather_description.csv

Task 2
docker-compose run --rm spark-app \
  python src/main.py task2 \
  data/raw/temperature.csv \
  data/raw/pressure.csv \
  data/raw/humidity.csv \
  data/raw/city_attributes.csv

Task 3
docker-compose run --rm spark-app \
  python src/main.py task3

ğŸ³ PerchÃ© Docker

Docker Ã¨ stato scelto per:

eliminare dipendenze locali (Java, Spark, Python)

garantire coerenza tra ambiente di sviluppo e test

semplificare la valutazione da parte del reviewer

Un singolo docker-compose.yml Ã¨ sufficiente per:

eseguire i job

lanciare i test

estendere il progetto

â˜¸ï¸ Integrazione con Kubernetes (Possibile Evoluzione)

In un contesto produttivo:

Il container Spark puÃ² essere eseguito su Spark on Kubernetes

I job possono diventare:

SparkApplication (Spark Operator)

job schedulati (Airflow / Argo)

I dataset possono risiedere su:

S3 / GCS / ADLS

Delta Lake

ğŸ”® Possibili Sviluppi Futuri

Introduzione di Delta Lake

Validazione schema con Great Expectations

Metriche e logging strutturato

CI/CD con GitHub Actions

Parametrizzazione completa via config file


Supporto multi-year e multi-timezone dinamico





